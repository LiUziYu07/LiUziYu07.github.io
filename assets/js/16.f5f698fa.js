(window.webpackJsonp=window.webpackJsonp||[]).push([[16],{423:function(t,a,v){"use strict";v.r(a);var r=v(2),_=Object(r.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"image-goal-navigation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#image-goal-navigation"}},[t._v("#")]),t._v(" Image Goal Navigation")]),t._v(" "),a("p",[t._v("有个问题，in real scene 是怎样收集数据进行fine tuning，然后在现实中使用。")]),t._v(" "),a("h1",{attrs:{id:"motivation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#motivation"}},[t._v("#")]),t._v(" Motivation")]),t._v(" "),a("p",[t._v("深度强化学习中存在两个问题：")]),t._v(" "),a("ol",[a("li",[t._v("对于新的目标泛化能力不足（actor-critic）")]),t._v(" "),a("li",[t._v("缺少数据，模型需要多个episodes 收敛（开发AI2-THOR框架，一套物理引擎）")])]),t._v(" "),a("h1",{attrs:{id:"contribution"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#contribution"}},[t._v("#")]),t._v(" Contribution")]),t._v(" "),a("ol",[a("li",[t._v("提出了DRL方法（在模拟器中进行训练）在没见过的target和scenes上取得了不错的泛化性能")]),t._v(" "),a("li",[t._v("提出了AI-THOR框架")]),t._v(" "),a("li",[t._v("在真机上验证")]),t._v(" "),a("li",[a("strong",[t._v("Mapless")])]),t._v(" "),a("li",[t._v("不使用"),a("strong",[t._v("三维重建")]),t._v("或者"),a("strong",[t._v("SLAM")])]),t._v(" "),a("li",[t._v("与其他RL方法相比，不需要对于新游戏重新进行训练，"),a("strong",[t._v("可泛化")])])]),t._v(" "),a("h3",{attrs:{id:"模拟器"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#模拟器"}},[t._v("#")]),t._v(" 模拟器")]),t._v(" "),a("p",[t._v("AI2THOR 模拟器，两个目的")]),t._v(" "),a("ol",[a("li",[t._v("物理引擎和DL framework直接交流（Online decision-making）")]),t._v(" "),a("li",[t._v("尽可能去"),a("strong",[t._v("模仿真实物体的外观")]),t._v("（影响模型的"),a("strong",[t._v("泛化能力")]),t._v("）")])]),t._v(" "),a("h4",{attrs:{id:"模拟器的结果"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#模拟器的结果"}},[t._v("#")]),t._v(" 模拟器的结果")]),t._v(" "),a("p",[t._v("四类场景：kitchen, living room, bedroom, and bathroom")]),t._v(" "),a("p",[t._v("一共32个场景，平均每个场景68个物体")]),t._v(" "),a("h2",{attrs:{id:"问题的定义"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#问题的定义"}},[t._v("#")]),t._v(" 问题的定义")]),t._v(" "),a("p",[t._v("给定目标位置图片，从起点出发用最少的步数到达目标位置")]),t._v(" "),a("h4",{attrs:{id:"网络结构"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#网络结构"}},[t._v("#")]),t._v(" 网络结构")]),t._v(" "),a("p",[t._v("Generic Siamese layers 所有场景共用")]),t._v(" "),a("p",[t._v("在同一个场景中的target共享scene-specific layer")]),t._v(" "),a("h2",{attrs:{id:"实验"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#实验"}},[t._v("#")]),t._v(" 实验")]),t._v(" "),a("p",[t._v("主要优势是对于新场景和新目标的泛化能力")]),t._v(" "),a("h4",{attrs:{id:"额外的实验"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#额外的实验"}},[t._v("#")]),t._v(" 额外的实验")]),t._v(" "),a("ol",[a("li",[t._v("动作空间连续")]),t._v(" "),a("li",[t._v("复杂真实场景下真机验证")])]),t._v(" "),a("p",[t._v("随机选取了32个场景中的20个场景的100个goals用于结果验证，指标用的是"),a("strong",[t._v("最短步数")])]),t._v(" "),a("h4",{attrs:{id:"提出的方法的优势"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#提出的方法的优势"}},[t._v("#")]),t._v(" 提出的方法的优势：")]),t._v(" "),a("ol",[a("li",[t._v("收敛快：data efficient，可能是因为跨target的"),a("strong",[t._v("权重共享")]),t._v("以及"),a("strong",[t._v("异步训练")]),t._v("机制")])]),t._v(" "),a("h5",{attrs:{id:"在机器人上测试时-用了三种方法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#在机器人上测试时-用了三种方法"}},[t._v("#")]),t._v(" 在机器人上测试时，用了三种方法")]),t._v(" "),a("ol",[a("li",[t._v("直接用真实照片训练模型2.")]),t._v(" "),a("li",[t._v("仅在20个模拟环境中训练scene-specific layers但是冻结generic layer")]),t._v(" "),a("li",[t._v("微调generic layer parameters")])])])}),[],!1,null,null,null);a.default=_.exports}}]);